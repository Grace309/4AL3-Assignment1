# 4AL3-Assignment1

## Files
- xiaot13_part1.py : Part 1 implementation (OLS vs Gradient Descent on GDP vs Happiness dataset)
- xiaot13_part2.py : Part 2 implementation (Linear Regression on Abalone dataset features)

## How to Run

### Part 1
1. Run the script:
python xiaot13_part1.py

2. The program will ask for the dataset path. Please provide the full path to:
gdp-vs-happiness.csv
(e.g., C:\Users\<username>\Desktop\Assignment1\datasets\gdp-vs-happiness.csv)

### Part 2
1. Run the script:
python xiaot13_part2.py

2. The program will ask for the dataset path. Please provide the full path to:
training_data.csv
(e.g., C:\Users\<username>\Desktop\Assignment1\datasets\training_data.csv)

### Output
Output figures are saved under 
part1_figures/
part2_figures/

## Requirements
The following Python packages are required:
- pandas
- numpy
- matplotlib
Install them with: pip install pandas numpy matplotlib


---

## Use of Generative AI
I used **ChatGPT (OpenAI GPT-5, cloud-based model)** to:
- Explain OLS and Gradient Descent concepts
- Provide debugging help for Python errors
- Suggest code structure (e.g., user input for dataset path, plot folder handling)
- Refine README and report writing

I did not use ChatGPT to generate final results or to run experiments; all experiments were run locally on my machine using Python.

### Carbon Footprint Estimate
Following the course policy:
- Model: ChatGPT (GPT-5)
- Hardware type: Cloud GPU/TPU (provider: OpenAI)
- Provider: OpenAI
- Region of compute: Hamilton
- Time used: ~8 hours of interaction for explanations, debugging, and writing
- Approximate estimate: ~50 queries × 4.32 gCO2 per query ≈ **216 gCO2**

---
